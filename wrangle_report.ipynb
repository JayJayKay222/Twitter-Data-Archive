{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would describe the efforts used the data wrangling process used in the project.\n",
    "The dataset used in this wrangling project are\n",
    "\n",
    "### - WeRateDogs (which is a twitter-archive-enhanced data) \n",
    "\n",
    " It was gotten from a Twitter Account @dog_rates who rates people's dogs with a humorous comment about the dog.\n",
    "### - tweet_json.txt\n",
    "\n",
    " Gotten from a queried Twitter API for each tweet's JSON data using Python's Tweepy library \n",
    "### - image_predictions.tsv \n",
    "\n",
    " Present in each tweet according to neural network. Hosted on the Udacity servers.\n",
    " \n",
    "The Project was completed on the Udacity Jupyter notebook Workspace.\n",
    "This wrangling process is divided into three stages -\n",
    "\n",
    "- Gathering Data \n",
    "- Assessing Data\n",
    "- Cleaning Data \n",
    "\n",
    "Let's dive deeper into each steps \n",
    "\n",
    "# 1. Gathering Data -\n",
    "\n",
    "The data used for thus project was gathered from 3 sources \n",
    "\n",
    "## (i) Twitter-Archive-Enhanced -\n",
    "\n",
    "    This data was downloaded manually from the provided link on the Udacity workspace and then uploaded on the machine and eventually read as a csv file into Pandas dataframe programmatically.\n",
    "    \n",
    " ## (ii) Image Predictions \n",
    " This was extracted by downloading the file programmatically using Requests library from the provided link. This data is. every image in the WeRateFogs Twitter archive through a neural network thaat classifies dogs into breeds.\n",
    " \n",
    "##  (iii) tweet.json.tst\n",
    "   This is an additional Twitter API data. It was obtained from querying the Twitter's API and then stored as txt file which was read line by line into pandas Dataframe.\n",
    "   \n",
    "   NOTE: Gathering this data requires a Twitter developer account but thee data used in this project were the provided data by Udacity. \n",
    "   I couldn't get access to the developer account.\n",
    "   \n",
    "  \n",
    "#  2. Assessing Data - \n",
    " \n",
    " After the gathering process the dataa extracted were assessed visually and programmatically to find Quality(content) issues and Tidiness(structural) issues before cleaning.\n",
    " \n",
    " ### A. Twitter-Enhanced-Archive\n",
    "  \n",
    "• Some rows are actually Retweets and not original tweets(which is needed for the analysis)\n",
    "• This confirms that the rating_denominator and rating_numerator have inconsistent data maybe due to recording data not related, not properly recording the values\n",
    "• The Timestamp column is a object data type instead of datetime\n",
    "• Timestamp column has extra characters +0000\n",
    "• Text column has links attached to it(This was not attended to in the cleaning process)\n",
    "• Dog stages are not in the same column\n",
    " \n",
    " ### B. Image-Predictions Data\n",
    "\n",
    "• The p1_dog column has false values that indicate that some rows are not a breed of dog\n",
    "• We only need these columns for the analysis = tweet_id, img_num, breed, confidence_level, p1_dog\n",
    "\n",
    "### C. Tweets Data - \n",
    "\n",
    "• The tweet_id column name appears to be id in this table\n",
    "• We only need the tweet_id, retweet_count and favourite_count columns \n",
    "\n",
    "# 3. CLEANING DATA - \n",
    "\n",
    "   These issues listed above were cleaned programmatically using pandas to have a tidy and quality data for Analysis and visualization.\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
